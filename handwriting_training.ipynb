{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["FplVyX99ZjzX","ERHB8JGHFasq","qlP5KfWpFhxw","E_pPGizBN0b0","PCywWXc1N6Zl","JJbhce7Xx1hm","lEXNJPlrOupo","grAVQrHqOxYD"],"mount_file_id":"1JmOsTK7MZ02iyzn-u_9Tsvj9UwLpnXCv","authorship_tag":"ABX9TyMMvHxzREcb8pwMHfY9trtc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# MMOCR Training\n","\n","This notebook contains all source code to train text detection and recognition models. You don't need to change anything except the path to datasets and config file modification. Please use GPU runtime."],"metadata":{"id":"unQLhztUxTeT"}},{"cell_type":"markdown","source":["## Setup for Training"],"metadata":{"id":"FplVyX99ZjzX"}},{"cell_type":"code","source":["!pip install torch==1.13.1+cu117 \\\n","  torchvision==0.14.1+cu117 \\\n","  --extra-index-url https://download.pytorch.org/whl/cu117\n","!pip install -U openmim\n","!mim install \"mmengine>=0.7.1,<1.1.0\"\n","!mim install \"mmcv>=2.0.0rc4,<2.1.0\"\n","!mim install \"mmdet>=3.0.0rc5,<3.2.0\"\n","!git clone https://github.com/open-mmlab/mmocr.git\n","!cd mmocr && pip install -v -e .\n","!apt install tree"],"metadata":{"id":"JJO1adsQEznO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset Preparation\n","\n","First, we need to change the format of the Label Studio annotation to MMOCR annotation."],"metadata":{"id":"ERHB8JGHFasq"}},{"cell_type":"markdown","source":["Load the dataset to local directory. **Change the script to load dataset that you get from from label-studio export based on your own need, but for convenience please put the dataset root at `/content/handwriting` directory**. The directory ideally structured like this (the filename may be different).\n","\n","```text\n","./handwriting\n","├── label-studio-anno.json\n","├── test\n","│   └── IMG_2347.jpg\n","└── training\n","    ├── IMG_2346.jpg\n","    ├── IMG_2348.jpg\n","    ├── IMG_2349.jpg\n","    └── IMG_2350.jpg\n","```"],"metadata":{"id":"SyvHe-ewxWyT"}},{"cell_type":"code","source":["!cp -r \"/content/drive/MyDrive/Public/Dibimbing/25 - OCR/Assignment/handwriting\" \"./handwriting\"\n","!tree \"./handwriting\""],"metadata":{"id":"Ubn2Wue3FGFD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the remaining cells of this section without modification."],"metadata":{"id":"CsXDPrj8DeEj"}},{"cell_type":"code","source":["import cv2\n","import json\n","import numpy as np\n","import os\n","import shutil\n","from pathlib import Path\n","from typing import Dict, List, Tuple"],"metadata":{"id":"h7_PvZRF6n67"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Functions for text detection dataset preparation.\n","The main function is `create_mmocr_det_anno`"],"metadata":{"id":"bYVJgiyFxzvo"}},{"cell_type":"code","source":["def xywh2xyxy(xywh: List[float], img_width: int, img_height: int) -> List[int]:\n","    \"\"\"\n","    Change bounding box format xywh normalized to xyxy\n","    \"\"\"\n","    x, y, w, h = xywh\n","    x = x * img_width / 100\n","    y = y * img_height / 100\n","    w = w * img_width / 100\n","    h = h * img_height / 100\n","    return [\n","        int(x),\n","        int(y),\n","        int(x + w),\n","        int(y + h),\n","    ]\n","\n","def xyxy2poly(xyxy: List[int]) -> List[int]:\n","    \"\"\"\n","    Change bounding box format from xyxy to polygon\n","    format xyxyxy...\n","    \"\"\"\n","    x1, y1, x2, y2 = xyxy\n","    return [\n","        x1, y1, x1, y2, x2, y2, x2, y1\n","    ]\n","\n","\n","def create_instance_mmocr_anno(\n","    label_ls: Dict,\n","    text: str,\n","    img_width: int,\n","    img_height: int,\n",") -> Dict:\n","    \"\"\"\n","    Conver annotation of a text instance from label studio format\n","    to MMOCR format\n","    \"\"\"\n","    bbox = xywh2xyxy(\n","        [\n","            label_ls[\"x\"],\n","            label_ls[\"y\"],\n","            label_ls[\"width\"],\n","            label_ls[\"height\"],\n","        ],\n","        img_width,\n","        img_height,\n","    )\n","    instance_anno = {}\n","    instance_anno[\"bbox\"] = bbox\n","    instance_anno[\"bbox_label\"] = 0\n","    instance_anno[\"polygon\"] = xyxy2poly(bbox)\n","    instance_anno[\"text\"] = text\n","    instance_anno[\"ignore\"] = False\n","    return instance_anno\n","\n","def create_image_mmocr_anno(image_name: str, image_ls: Dict) -> Dict:\n","    \"\"\"\n","    Conver annotation of an image from label studio format\n","    to MMOCR format\n","    \"\"\"\n","    img_width = image_ls[\"label\"][0][\"original_width\"]\n","    img_height = image_ls[\"label\"][0][\"original_height\"]\n","    image_anno = {}\n","    image_anno[\"img_path\"] = image_name\n","    image_anno[\"height\"] = img_height\n","    image_anno[\"width\"] = img_width\n","    image_anno[\"instances\"] = [\n","        create_instance_mmocr_anno(lbl, txt, img_width, img_height)\n","        for lbl, txt in zip(image_ls[\"label\"], image_ls[\"transcription\"])\n","    ]\n","    return image_anno\n","\n","def create_metainfo_det() -> Dict:\n","    \"\"\"\n","    Metainfo for MMOCR text detection dataset\n","    \"\"\"\n","    return {\n","        \"dataset_type\": \"TextDetDataset\",\n","        \"task_name\": \"textdet\",\n","        \"category\": [{\"id\": 0, \"name\": \"text\"}],\n","    }\n","\n","def create_output_json(\n","    annotations: List[Dict],\n","    metainfo: Dict,\n","    output_path: Path\n",") -> None:\n","    \"\"\"\n","    Dump MMOCR annotation JSON\n","    \"\"\"\n","    output = {\n","        \"metainfo\": metainfo,\n","        \"data_list\": annotations\n","    }\n","    with open(output_path, \"w\") as f:\n","        json.dump(output, f)\n","\n","def get_image_name(ls_image_path: str) -> str:\n","    \"\"\"\n","    Label studio will write the image file name in format of\n","    '{random_id}-{original_image_name}'. So we only want to\n","    get the original image name, since that is the name that\n","    we have.\n","    \"\"\"\n","    name = os.path.basename(ls_image_path)\n","    name = name[(name.find(\"-\") + 1):]\n","    return name\n","\n","def create_mmocr_det_anno(\n","    ls_anno_path: Path,\n","    train_images_dir: Path,\n","    test_images_dir: Path,\n","    output_dir: Path,\n","):\n","    \"\"\"\n","    Create text detection dataset in MMOCR format\n","    \"\"\"\n","    train_images = [p for p in train_images_dir.glob(\"*\")]\n","    test_images = [p for p in test_images_dir.glob(\"*\")]\n","    with open(ls_anno_path, \"r\") as f:\n","        ls_anno = json.load(f)\n","    image_annos = {}\n","    for ann in ls_anno:\n","        img_name = get_image_name(ann[\"ocr\"])\n","        image_annos[img_name] = create_image_mmocr_anno(img_name, ann)\n","\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","    for p in [*train_images, *test_images]:\n","      shutil.copy(p, output_dir / p.name)\n","    create_output_json(\n","        annotations=[image_annos[p.name] for p in train_images],\n","        metainfo=create_metainfo_det(),\n","        output_path=output_dir / \"textdet_train.json\"\n","    )\n","    create_output_json(\n","        annotations=[image_annos[p.name] for p in test_images],\n","        metainfo=create_metainfo_det(),\n","        output_path=output_dir / \"textdet_test.json\"\n","    )"],"metadata":{"id":"Bd8rEfNYUCX9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Functions for text recognition dataset preparation. The main function is `create_mmocr_rec_anno`"],"metadata":{"id":"RaTA3CZxx4vF"}},{"cell_type":"code","source":["def create_metainfo_rec() -> Dict:\n","    \"\"\"\n","    Metainfo for MMOCR text recognition dataset\n","    \"\"\"\n","    return {\n","        \"dataset_type\": \"TextRecogDataset\",\n","        \"task_name\": \"textrecog\",\n","    }\n","\n","def crop_images(\n","    src_annos: Dict,\n","    image_src_dir: Path,\n","    image_dst_dir: Path,\n",") -> List[Dict]:\n","    \"\"\"\n","    Crop text images and extract the text annotations\n","    \"\"\"\n","    image_path = image_src_dir / src_annos[\"img_path\"]\n","    image = cv2.imread(str(image_path))\n","    image_name = image_path.stem\n","\n","    anns = []\n","    for i, src_txt_anno in enumerate(src_annos[\"instances\"]):\n","        dst_image_file = f\"{image_name}_{i:05}.jpg\"\n","        x1, y1, x2, y2 = src_txt_anno[\"bbox\"]\n","        crop = image[y1:y2, x1:x2]\n","        cv2.imwrite(str(image_dst_dir / dst_image_file), crop)\n","\n","        instance = [{\"text\": src_txt_anno[\"text\"]}]\n","        crop_ann = {\n","            \"img_path\": dst_image_file,\n","            \"height\": crop.shape[0],\n","            \"width\": crop.shape[1],\n","            \"instances\": instance\n","        }\n","        anns.append(crop_ann)\n","    return anns\n","\n","\n","def create_split_anno(\n","    det_anno_path: Path,\n","    det_images_dir: Path,\n","    output_dir: Path,\n","    json_name: str,\n","):\n","    \"\"\"\n","    Create formatted text recognition dataset for\n","    a dataset split.\n","    \"\"\"\n","    with open(det_anno_path, \"r\") as f:\n","        det_anno = json.load(f)\n","    new_data_list = []\n","    for src_anno in det_anno[\"data_list\"]:\n","        new_data_list += crop_images(\n","            src_anno,\n","            det_images_dir,\n","            output_dir,\n","        )\n","    new_anno = {\n","        \"metainfo\": create_metainfo_rec(),\n","        \"data_list\": new_data_list,\n","    }\n","    with open(output_dir / json_name, \"w\") as f:\n","      json.dump(new_anno, f)\n","\n","def create_mmocr_rec_anno(\n","    det_root_dir: Path,\n","    output_dir: Path,\n","):\n","    \"\"\"\n","    Create text recognition dataset in MMOCR format\n","    \"\"\"\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","    create_split_anno(\n","        det_root_dir / \"textdet_train.json\",\n","        det_root_dir,\n","        output_dir,\n","        \"textrecog_train.json\"\n","    )\n","    create_split_anno(\n","        det_root_dir / \"textdet_test.json\",\n","        det_root_dir,\n","        output_dir,\n","        \"textrecog_test.json\"\n","    )"],"metadata":{"id":"UuoJzUjX6C8E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Do the actual format conversions."],"metadata":{"id":"wH30dfFax6oE"}},{"cell_type":"code","source":["# change to path to your label-studio annotation JSON\n","LABEL_STUDIO_ANN = Path(\"handwriting/label-studio-anno.json\")\n","# change to path to your training images folder\n","TRAIN_IMGS = Path(\"handwriting/training\")\n","# change to path to your test images folder\n","TEST_IMGS = Path(\"handwriting/test\")\n","# formatted dataset for text detection will be saved in the directory below\n","OUTPUT_DET_DIR = Path(\"dataset-det\")\n","# formatted dataset for text recognition will be saved in the directory below\n","OUTPUT_REC_DIR = Path(\"dataset-rec\")\n","\n","create_mmocr_det_anno(\n","    LABEL_STUDIO_ANN,\n","    TRAIN_IMGS,\n","    TEST_IMGS,\n","    OUTPUT_DET_DIR,\n",")\n","create_mmocr_rec_anno(\n","    OUTPUT_DET_DIR,\n","    OUTPUT_REC_DIR,\n",")"],"metadata":{"id":"uNIstUXZEV9o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You should see two new folders `dataset-det` and `dataset-rec` now."],"metadata":{"id":"0heKC6D5DWQ5"}},{"cell_type":"markdown","source":["## Text Detection Training\n","\n","I already provide the config and scripts that you can use. You only need to runn the cell one-by-one to start the training. Please upload `handwriting-dbnet-config.py` to this notebook directory."],"metadata":{"id":"qlP5KfWpFhxw"}},{"cell_type":"markdown","source":["### Config Details\n","\n","However, in the next cell I put some expanations about the config file. The changes already implemented in the provided `.py` file that you have uploaded, so this is only for your additional reading."],"metadata":{"id":"E_pPGizBN0b0"}},{"cell_type":"markdown","source":["We will be using the config file `/content/mmocr/configs/textdet/dbnet/dbnet_resnet50-dcnv2_fpnc_1200e_icdar2015.py` as the main model config. Note that each parameters can be defined in another `.py` file, since MMOCR uses distributed configuration files. Check the `_base_` of the main config.\n","\n","Change in the configuration:\n","\n","- Root data (Use ICDAR2015 config) to `dataset-det`\n","- Num of iterations, try at least 50, be careful to not overfit\n","- Validation cycle, try around 10 iters\n","- TensorBoard visualizer\n","\n","  ```\n","  vis_backends = [dict(type='LocalVisBackend'),\n","                  dict(type='TensorboardVisBackend')]\n","  ```\n","\n","- Only save last checkpoint\n","\n","  ```\n","      checkpoint=dict(type='CheckpointHook', interval=10, max_keep_ckpts=1)\n","  ```"],"metadata":{"id":"yehNoxk0Nbqr"}},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"PCywWXc1N6Zl"}},{"cell_type":"markdown","source":["Run the following cell, check `/content/vis` and make sure that the visualization is correct. If not, there might be something wrong with your config."],"metadata":{"id":"eKtFH-VqvO73"}},{"cell_type":"code","source":["!python /content/mmocr/tools/visualizations/browse_dataset.py \\\n","  \"/content/handwriting-dbnet-config.py\" \\\n","  -o \"/content/vis\" \\\n","  -m original"],"metadata":{"id":"BbUFpj3yKpiS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir \"/content/work_dir_det\""],"metadata":{"id":"t2EZH1o4IH7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python \"/content/mmocr/tools/train.py\" \\\n","  \"/content/handwriting-dbnet-config.py\" \\\n","  --work-dir \"/content/work_dir_det\""],"metadata":{"id":"DsOxllSOJ9DW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Optionally, save the results to your GDrive"],"metadata":{"id":"Ec4RRgRryrwZ"}},{"cell_type":"code","source":["!cp -r \"/content/work_dir_det\" \"/content/drive/MyDrive/Public/Dibimbing/25 - OCR/Kunci Jawaban/dbnet_training\""],"metadata":{"id":"2zKAQLjpVB1J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Text Recognition Training\n","\n","I already provide the config and scripts that you can use. You only need to runn the cell one-by-one to start the training. Please upload `handwriting-svtr-config.py` to this notebook directory."],"metadata":{"id":"JJbhce7Xx1hm"}},{"cell_type":"markdown","source":["### Config Details\n","\n","However, in the next cell I put some expanations about the config file. The changes already implemented in the provided `.py` file that you have uploaded, so this is only for your additional reading."],"metadata":{"id":"lEXNJPlrOupo"}},{"cell_type":"markdown","source":["We will be using the config file `/content/mmocr/configs/textrecog/svtr/svtr-base_20e_st_mj.py` as the main model config. Note that each parameters can be defined in another `.py` file, since MMOCR uses distributed configuration files. Check the `_base_` of the main config.\n","\n","Change in the configuration:\n","\n","- Root data (Use ICDAR2015 config) to `dataset-rec`\n","- Num of iterations, try the default fist.\n","- TensorBoard visualizer\n","\n","  ```\n","  vis_backends = [dict(type='LocalVisBackend'),\n","                  dict(type='TensorboardVisBackend')]\n","  ```\n","\n","- Only save last checkpoint\n","\n","  ```\n","      checkpoint=dict(type='CheckpointHook', interval=1, max_keep_ckpts=1)\n","  ```\n","\n","- Validation evaluator\n","\n","  ```\n","  val_evaluator = dict(\n","      _delete_=True,\n","      type='Evaluator',\n","      metrics=[\n","          dict(\n","              type='WordMetric',\n","              mode=['exact', 'ignore_case', 'ignore_case_symbol']),\n","          dict(type='CharMetric')\n","      ])\n","  test_evaluator = val_evaluator\n","  ```\n","\n","- Train/test dataset list\n","\n","  ```\n","  train_list = [_base_.icdar2015_textrecog_train]\n","  test_list = [_base_.icdar2015_textrecog_test]\n","  ```\n","\n","- Update pre-trained model\n","\n","  ```\n","  load_from = \"https://download.openmmlab.com/mmocr/textrecog/svtr/svtr-base_20e_st_mj/svtr-base_20e_st_mj-ea500101.pth\"\n","  ```\n","\n","- Change batch size to smaller value if you get CUDA OOM, e.g. 128"],"metadata":{"id":"Qzzc5jW5x4aP"}},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"grAVQrHqOxYD"}},{"cell_type":"markdown","source":["Run the following cell, check `/content/vis` and make sure that the visualization is correct. If not, there might be something wrong with your config."],"metadata":{"id":"ZFspLR3Ku9HL"}},{"cell_type":"code","source":["!python /content/mmocr/tools/visualizations/browse_dataset.py \\\n","  \"/content/handwriting-svtr-config.py\" \\\n","  -o \"/content/vis\" \\\n","  -m original"],"metadata":{"id":"0zYeprXQA8qA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir \"/content/work_dir_rec\""],"metadata":{"id":"Qflmo8uuz_D-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python \"/content/mmocr/tools/train.py\" \\\n","  \"/content/handwriting-svtr-config.py\" \\\n","  --work-dir \"/content/work_dir_rec\""],"metadata":{"id":"LpiqFfra0GRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r \"/content/work_dir_rec\" \"/content/drive/MyDrive/Public/Dibimbing/25 - OCR/Kunci Jawaban/svtr_training\""],"metadata":{"id":"dolznvv6JgO1"},"execution_count":null,"outputs":[]}]}